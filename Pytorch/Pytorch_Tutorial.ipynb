{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/Pytorch/Pytorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHILOGjOQbsQ"
      },
      "source": [
        "# **Pytorch Tutorial**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C1zA7GupxdJv"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eqj90EkWbWx"
      },
      "source": [
        "**1. Pytorch Documentation Explanation with torch.max**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JCXOg-iSQuk7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5333, -2.1289,  0.0134,  0.2944,  1.3323],\n",
            "        [-0.3073,  0.7287, -0.3138, -0.5779, -0.4857],\n",
            "        [ 2.1097,  0.7444, -0.6332, -2.2748, -0.6700],\n",
            "        [-0.6998,  0.4827, -0.1669,  0.3563,  0.1973]])\n",
            "tensor([[-0.3793,  0.2745, -0.3627,  0.7330, -1.1814],\n",
            "        [ 0.7172,  0.3911, -0.8705, -0.6460, -1.2681],\n",
            "        [-1.2629,  0.6069,  0.7654,  0.6288, -1.1020],\n",
            "        [-0.8329, -1.8591,  0.6841,  0.0319,  0.4117]])\n",
            "tensor([[ 1.2418,  0.0421, -0.1323,  0.4641,  1.5034],\n",
            "        [-1.6918,  2.5436,  0.4511, -0.7256, -1.2441],\n",
            "        [-0.7143, -0.4768, -0.0450, -0.7399,  0.5821],\n",
            "        [-0.3500, -0.1162,  0.5992,  0.4575,  1.7788]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4,5)\n",
        "y = torch.randn(4,5)\n",
        "z = torch.randn(4,5)\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EEqa9GFoWF78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1097)\n"
          ]
        }
      ],
      "source": [
        "# 1. max of entire tensor (torch.max(input) → Tensor)\n",
        "m = torch.max(x)\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wffThGDyWKxJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.1097, 0.7444, 0.0134, 0.3563, 1.3323])\n",
            "tensor([2, 2, 0, 3, 0])\n"
          ]
        }
      ],
      "source": [
        "# 2. max along a dimension (torch.max(input, dim, keepdim=False, *, out=None) → (Tensor, LongTensor))\n",
        "m, idx = torch.max(x,0)\n",
        "print(m)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oKDQW3tIXKg-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.1097, 0.7444, 0.0134, 0.3563, 1.3323])\n",
            "tensor([2, 2, 0, 3, 0])\n"
          ]
        }
      ],
      "source": [
        "# 2-2\n",
        "m, idx = torch.max(input=x,dim=0)\n",
        "print(m)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QZ6WRLyX3De"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.1097, 0.7444, 0.0134, 0.3563, 1.3323])\n",
            "tensor([2, 2, 0, 3, 0])\n"
          ]
        }
      ],
      "source": [
        "# 2-3\n",
        "# keepdim = False represents that the output tensor will not retain the reduced dimension.\n",
        "m, idx = torch.max(x,0,False)\n",
        "print(m)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqGuctkKbUEn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2.1097, 0.7444, 0.0134, 0.3563, 1.3323]])\n",
            "tensor([[2, 2, 0, 3, 0]])\n"
          ]
        }
      ],
      "source": [
        "# 2-4\n",
        "# keepdim = True represents that the output tensor will retain the reduced dimension.\n",
        "m, idx = torch.max(x,dim=0,keepdim=True)\n",
        "print(m)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9OMzxuMlZPIu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.1097, 0.7444, 0.0134, 0.3563, 1.3323])\n",
            "tensor([2, 2, 0, 3, 0])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1805735/1447715753.py:3: UserWarning: An output with one or more elements was resized since it had shape [1, 5], which does not match the required output shape [5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:31.)\n",
            "  torch.max(x,0,False,out=p)\n"
          ]
        }
      ],
      "source": [
        "# 2-5\n",
        "p = (m,idx)\n",
        "torch.max(x,0,False,out=p)\n",
        "print(p[0])\n",
        "print(p[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uhd4TqGTbD2c"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "max() received an invalid combination of arguments - got (Tensor, int, bool, tuple), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, Tensor other, *, Tensor out = None)\n      didn't match because some of the arguments have invalid types: (Tensor, !int!, !bool!, !tuple of (Tensor, Tensor)!)\n * (Tensor input, int dim, bool keepdim = False, *, tuple of Tensors out = None)\n * (Tensor input, name dim, bool keepdim = False, *, tuple of Tensors out = None)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 2-6\u001b[39;00m\n\u001b[1;32m      2\u001b[0m p \u001b[38;5;241m=\u001b[39m (m,idx)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(p[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(p[\u001b[38;5;241m1\u001b[39m])\n",
            "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (Tensor, int, bool, tuple), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, Tensor other, *, Tensor out = None)\n      didn't match because some of the arguments have invalid types: (Tensor, !int!, !bool!, !tuple of (Tensor, Tensor)!)\n * (Tensor input, int dim, bool keepdim = False, *, tuple of Tensors out = None)\n * (Tensor input, name dim, bool keepdim = False, *, tuple of Tensors out = None)\n"
          ]
        }
      ],
      "source": [
        "# 2-6\n",
        "p = (m,idx)\n",
        "torch.max(x,0,False,p)\n",
        "print(p[0])\n",
        "print(p[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wbxjUSOXxN0n"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "max() received an invalid combination of arguments - got (Tensor, bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, Tensor other, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, tuple of Tensors out = None)\n * (Tensor input, name dim, bool keepdim = False, *, tuple of Tensors out = None)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 2-7\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m m, idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (Tensor, bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, Tensor other, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, tuple of Tensors out = None)\n * (Tensor input, name dim, bool keepdim = False, *, tuple of Tensors out = None)\n"
          ]
        }
      ],
      "source": [
        "# 2-7\n",
        "m, idx = torch.max(x,True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMwhGLlGWYaR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5333,  0.2745,  0.0134,  0.7330,  1.3323],\n",
            "        [ 0.7172,  0.7287, -0.3138, -0.5779, -0.4857],\n",
            "        [ 2.1097,  0.7444,  0.7654,  0.6288, -0.6700],\n",
            "        [-0.6998,  0.4827,  0.6841,  0.3563,  0.4117]])\n"
          ]
        }
      ],
      "source": [
        "# 3. max(choose max) operators on two tensors (torch.max(input, other, *, out=None) → Tensor)\n",
        "# 选择每一个位置上的最大值\n",
        "# choose max value between two tensors\n",
        "t = torch.max(x,y)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFxRKu2Dedwb"
      },
      "source": [
        "**2. Common errors**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMcRyMxGwhul"
      },
      "source": [
        "The following code blocks show some common errors while using the torch library. First, execute the code with error, and then execute the next code block to fix the error. You need to change the runtime to GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eX-kKdi6ynFf"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "-muJ4KKreoP2",
        "outputId": "c1d5c3a5-9540-4145-d80c-3cbca18a1deb"
      },
      "outputs": [],
      "source": [
        "# 1. different device error\n",
        "model = torch.nn.Linear(5,1).to(\"cuda:0\")\n",
        "x = torch.Tensor([1,2,3,4,5]).to(\"cpu\")\n",
        "y = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a54PqxJLe9-c",
        "outputId": "909d3693-236f-4419-f269-8fb443ef7534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "# 1. different device error (fixed)\n",
        "x = torch.Tensor([1,2,3,4,5]).to(\"cuda:0\")\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "n7OHtZwbi7Qw",
        "outputId": "2a7d2dd0-6498-4da0-9591-3554c1739046"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7fa8b244df3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# 2. mismatched dimensions error\n",
        "x = torch.randn(4,5)\n",
        "y= torch.randn(5,4)\n",
        "z = x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVynzvrskFCD",
        "outputId": "926dc01c-be6f-48e1-ad39-a5bcecebc513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 5])\n"
          ]
        }
      ],
      "source": [
        "# 2. mismatched dimensions error (fixed)\n",
        "y= y.transpose(0,1)\n",
        "z = x + y\n",
        "print(z.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Hgzgb9gJANod",
        "outputId": "21b58850-b3f1-4f2a-db5d-cc45e47ccbea"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 7.27 GiB. GPU 0 has a total capacity of 23.52 GiB of which 355.81 MiB is free. Process 3151197 has 21.31 GiB memory in use. Including non-PyTorch memory, this process has 1.80 GiB memory in use. Of the allocated memory 1.41 GiB is allocated by PyTorch, and 19.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m resnet18 \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet18()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Neural Networks for Image Recognition\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2048\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m244\u001b[39m,\u001b[38;5;241m244\u001b[39m) \u001b[38;5;66;03m# Create fake data (512 images)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mresnet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Use Data as Input and Feed to Model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.27 GiB. GPU 0 has a total capacity of 23.52 GiB of which 355.81 MiB is free. Process 3151197 has 21.31 GiB memory in use. Including non-PyTorch memory, this process has 1.80 GiB memory in use. Of the allocated memory 1.41 GiB is allocated by PyTorch, and 19.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# 3. cuda out of memory error\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "resnet18 = models.resnet18().to(\"cuda:0\") # Neural Networks for Image Recognition\n",
        "data = torch.randn(2048,3,244,244) # Create fake data (512 images)\n",
        "out = resnet18(data.to(\"cuda:0\")) # Use Data as Input and Feed to Model\n",
        "print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPksKnB_w343",
        "outputId": "fbee46ad-e63e-4bfc-8971-452895dd7a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ],
      "source": [
        "# 3. cuda out of memory error (fixed)\n",
        "for d in data:\n",
        "  out = resnet18(d.to(\"cuda:0\").unsqueeze(0))\n",
        "print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.7820e-01, -6.7507e-01, -2.4757e-01,  2.5081e-02, -1.6184e-01,\n",
            "          8.0630e-02, -1.0595e-01,  1.3599e-02, -2.0529e-01,  2.1550e-01,\n",
            "         -5.9498e-01,  5.5215e-02, -1.3171e-01,  2.6458e-01, -5.4338e-01,\n",
            "          2.1331e-01,  3.8900e-01, -3.2000e-01, -4.9684e-01,  1.2532e+00,\n",
            "          6.1842e-01, -4.4870e-01, -4.4976e-02, -3.2155e-01, -4.9260e-01,\n",
            "          2.0059e-01,  3.1546e-01,  1.1004e+00,  3.8112e-01, -7.8669e-01,\n",
            "         -7.4259e-01,  3.8865e-01,  6.2221e-01, -2.2290e-01, -6.9785e-02,\n",
            "         -1.2549e-01,  3.9365e-01,  4.2896e-01,  2.9827e-01,  6.2066e-01,\n",
            "          1.6700e-01,  8.3207e-01,  2.1306e-01, -1.1544e-01, -1.8049e-01,\n",
            "         -4.3651e-01,  5.8072e-01,  3.7959e-01, -8.2450e-02,  4.7491e-01,\n",
            "          5.1069e-02,  5.3747e-01,  5.8149e-01, -1.3893e-01, -7.0281e-01,\n",
            "         -3.7909e-01, -9.0739e-01,  1.9776e-01,  3.1438e-01, -3.2686e-03,\n",
            "         -1.4422e-01, -7.7786e-02,  4.7470e-01, -1.8298e-01, -8.6349e-02,\n",
            "         -5.8126e-01,  1.7504e-01,  3.1554e-01, -1.0841e-01,  3.0876e-01,\n",
            "         -8.5877e-01, -5.5025e-01, -2.3658e-01, -3.7591e-01,  3.2275e-02,\n",
            "         -4.0980e-01, -1.8777e-01, -2.4798e-01, -4.3600e-02,  7.9296e-01,\n",
            "         -2.9949e-01, -5.4672e-01, -7.7361e-02,  1.3802e+00,  7.2693e-01,\n",
            "         -7.0802e-01, -6.6684e-01,  1.0240e-01,  2.5580e-01, -3.1209e-01,\n",
            "         -4.7821e-01,  2.4866e-02,  1.9334e-01, -1.0207e-01,  1.3077e-01,\n",
            "         -5.0143e-01, -4.1144e-02, -1.8333e-01,  6.6049e-01, -4.6899e-01,\n",
            "         -6.7547e-01,  3.4334e-03,  8.6811e-01,  4.0157e-01,  3.3907e-01,\n",
            "         -6.2126e-01, -5.1962e-01, -4.8741e-01,  3.8802e-01, -1.0491e+00,\n",
            "          5.6043e-02,  3.6275e-01,  2.3469e-02, -3.9287e-01,  3.6405e-01,\n",
            "         -9.7916e-01, -2.2761e-01, -3.0377e-01,  2.2211e-01,  1.7668e-01,\n",
            "         -6.8652e-02,  8.7006e-01, -3.4741e-02, -4.0687e-01, -9.2142e-01,\n",
            "         -5.6709e-01, -3.2049e-01, -2.4122e-01,  7.0763e-01,  1.2355e+00,\n",
            "          1.0080e+00, -8.9127e-01,  1.7747e-01,  2.4349e-01,  1.0226e-02,\n",
            "         -9.0904e-01,  3.9231e-01, -2.1601e-03, -4.4077e-01,  3.5616e-02,\n",
            "          2.3213e-01, -5.8040e-01, -1.2315e-02, -2.4021e-01,  8.8094e-01,\n",
            "         -5.4922e-01, -5.0743e-02,  6.5153e-01, -2.9121e-01, -2.2394e-01,\n",
            "          5.7471e-01, -5.6944e-01, -5.0771e-02,  5.3331e-01,  2.4854e-01,\n",
            "          5.0085e-01, -7.0722e-01, -8.5881e-01, -6.2070e-01,  6.7609e-01,\n",
            "          3.4539e-01,  2.6597e-01, -4.9666e-02, -1.0280e-02, -1.3179e-01,\n",
            "         -1.4341e+00, -4.7995e-02, -1.1326e-02,  4.7794e-01,  2.0605e-01,\n",
            "          1.1907e-01, -6.2562e-01,  8.7111e-01,  6.8178e-01,  1.0780e+00,\n",
            "          5.9510e-01,  3.2415e-02,  9.9440e-02, -2.7961e-01, -6.2885e-01,\n",
            "          1.5375e-01, -6.7207e-01, -8.9134e-01,  2.0945e-01,  3.5836e-01,\n",
            "         -2.5955e-02, -4.0712e-01,  1.4551e-01,  1.4217e-01, -3.0322e-01,\n",
            "          9.4933e-02, -2.6661e-01, -6.8703e-01, -2.6336e-02,  4.9777e-02,\n",
            "          6.2380e-02,  5.7419e-02,  1.0633e+00, -1.9963e-01,  3.6488e-01,\n",
            "          7.0988e-01,  1.7546e-02,  1.3255e-01, -6.5786e-02,  4.1838e-02,\n",
            "          3.6089e-01, -7.4394e-01, -8.7204e-01, -6.1092e-01,  4.9568e-01,\n",
            "          3.0649e-01, -4.3707e-01,  8.5826e-02, -8.7041e-02,  5.7631e-01,\n",
            "          6.6086e-01, -9.1529e-02, -3.7761e-01, -2.2230e-01,  3.0335e-01,\n",
            "          6.7735e-01,  1.1046e+00,  1.6924e+00, -2.2654e-01,  8.6679e-01,\n",
            "          3.0978e-01, -1.1580e-01,  1.4378e-01, -5.8613e-01,  7.8044e-01,\n",
            "          4.2331e-01, -1.0256e-01,  2.1247e-01,  2.3722e-01, -6.7715e-01,\n",
            "          5.0430e-02,  4.9838e-01, -1.2511e-01, -3.7443e-01, -4.6966e-01,\n",
            "         -3.3211e-01,  2.7513e-01, -3.3689e-01, -3.7853e-03, -2.7875e-01,\n",
            "         -1.0834e-01, -1.8637e-01,  5.4936e-01,  2.5341e-01, -2.0112e-01,\n",
            "         -4.2624e-01,  1.4608e-01,  6.1650e-01, -1.6719e-02,  6.1016e-01,\n",
            "         -6.2547e-01,  2.5522e-01,  6.1821e-01,  5.2287e-01,  5.9292e-02,\n",
            "          4.9016e-01, -3.9619e-01, -7.4435e-01, -2.7064e-01, -2.3358e-01,\n",
            "          1.7019e-01,  3.8471e-01,  6.6684e-01,  9.1193e-01, -6.1735e-01,\n",
            "          5.6453e-02, -6.6490e-01,  4.9437e-01,  1.0176e-01, -5.3927e-01,\n",
            "          4.9539e-01,  1.4891e-01,  2.2124e-01,  8.0903e-01, -5.5671e-01,\n",
            "          3.4028e-01,  4.4735e-01,  7.1435e-02, -3.0527e-02, -7.7767e-01,\n",
            "          5.9844e-02, -4.9640e-01,  2.1782e-03,  5.2236e-02,  4.5375e-01,\n",
            "         -1.3599e-01,  1.5027e-03, -6.8961e-01, -1.9283e-01, -2.3652e-01,\n",
            "          4.5115e-02, -6.2932e-02,  3.1717e-01, -2.0226e-01,  2.5364e-01,\n",
            "          2.4907e-01, -1.2616e+00,  2.6776e-02,  6.2634e-01, -1.9616e-01,\n",
            "         -5.9442e-01,  6.0034e-01, -3.8002e-01, -1.0797e-01,  5.4277e-01,\n",
            "          1.4019e+00,  5.9696e-01,  5.2634e-01,  3.3843e-01, -5.0468e-02,\n",
            "          1.1691e-01, -5.4375e-02,  1.1483e+00, -1.8301e-01,  1.0688e+00,\n",
            "          3.0027e-01,  7.3923e-01, -8.7015e-02,  4.6156e-01,  1.7340e-01,\n",
            "         -1.1577e-02,  5.6297e-01, -1.3148e-01, -4.3912e-01, -1.4508e-02,\n",
            "         -2.0974e-01, -1.8966e-01, -4.3461e-01, -8.1656e-01,  6.8714e-01,\n",
            "         -5.4058e-01, -2.6345e-01,  1.3623e-02,  4.9085e-01, -1.8266e-01,\n",
            "         -6.1993e-01, -6.5607e-02, -3.8645e-01, -4.4030e-01, -2.0440e-01,\n",
            "          2.1112e-01, -1.9316e-01,  2.6976e-01,  1.6832e-01,  3.9932e-01,\n",
            "          6.0637e-01, -4.5286e-02,  8.6519e-01, -4.7277e-01, -1.9388e-01,\n",
            "         -8.2605e-02,  7.8451e-02, -2.4296e-01,  3.5012e-01, -5.2209e-01,\n",
            "          5.4706e-01,  1.7492e-01,  4.3082e-01, -5.9776e-01, -8.5188e-01,\n",
            "          8.0547e-01,  8.8181e-01, -2.1557e-01, -1.1307e+00, -1.4984e-01,\n",
            "         -4.2536e-02, -6.6961e-02, -4.8341e-02, -2.0914e-01,  5.7929e-01,\n",
            "         -3.6218e-01,  1.9075e-01, -6.3896e-01,  6.1922e-01, -1.3041e-01,\n",
            "          4.6590e-02,  3.8719e-01,  3.2038e-01,  3.4017e-01,  6.5426e-02,\n",
            "          2.4118e-02, -3.1757e-01, -2.3257e-01, -8.0403e-02, -1.8910e-01,\n",
            "          4.2984e-01, -1.5662e-01, -9.0196e-02,  5.4523e-02, -3.2488e-02,\n",
            "          7.2857e-01,  6.4035e-02, -7.7746e-01,  5.0229e-01, -1.0514e-01,\n",
            "          9.5731e-01, -1.0056e+00, -1.5921e-01,  5.1338e-01, -2.8832e-02,\n",
            "         -1.4496e-01,  7.2387e-01, -1.1905e-01,  1.2613e+00, -7.7893e-01,\n",
            "         -3.6809e-01,  1.0142e+00,  4.2297e-01,  3.5136e-01, -8.3115e-01,\n",
            "          2.5542e-01,  1.5790e-01,  4.0892e-02, -7.1015e-01, -1.1766e+00,\n",
            "          1.6213e-01,  2.0350e-01,  7.8465e-01, -8.9688e-01, -4.6388e-01,\n",
            "         -8.8835e-02, -5.4611e-01,  9.3750e-01, -5.9926e-02,  2.8526e-01,\n",
            "          3.3439e-02, -4.6354e-01, -2.7903e-01,  3.9365e-01,  3.2310e-01,\n",
            "          6.5147e-01, -4.4405e-01, -1.3698e-01,  6.6481e-02, -3.2094e-01,\n",
            "          8.6359e-02,  2.6327e-01, -5.2072e-01,  2.3115e-01, -6.1881e-01,\n",
            "          6.8949e-01, -6.1006e-01, -9.8069e-01, -3.2764e-01, -6.1652e-01,\n",
            "         -3.3949e-01,  8.4584e-01,  7.5133e-01,  6.1707e-01,  7.8125e-01,\n",
            "         -3.8248e-01,  1.5039e-01, -3.4707e-01,  5.8502e-01, -5.8475e-01,\n",
            "         -5.0475e-01,  2.1951e-01, -3.4795e-02,  3.8838e-01, -3.4356e-01,\n",
            "          4.9655e-01, -1.6021e-01,  6.3755e-01,  5.2303e-01,  3.4694e-02,\n",
            "         -2.7151e-01, -6.4880e-02,  8.2471e-01, -4.2328e-01,  1.7359e-01,\n",
            "         -9.6617e-02,  7.2592e-01,  2.0644e-02,  1.0614e-01,  5.4897e-01,\n",
            "          7.6096e-01, -1.0375e-01, -5.7978e-01, -1.9978e-01,  2.5606e-01,\n",
            "          7.7424e-02, -6.3538e-01, -1.0459e+00, -3.0691e-01,  5.8512e-01,\n",
            "          6.5949e-02,  4.5213e-01,  8.7843e-01,  5.7948e-01,  5.8047e-03,\n",
            "         -5.9150e-01, -1.6681e-01, -1.0100e+00, -4.9578e-01,  3.8309e-01,\n",
            "          2.3287e-01,  2.3987e-01,  8.1067e-01, -5.6730e-01, -2.6577e-01,\n",
            "          3.7724e-01, -9.7129e-01, -1.4627e-02, -1.8911e-01,  5.7907e-01,\n",
            "          3.3408e-01, -2.6112e-01, -8.7611e-02,  2.0201e-01,  6.2316e-01,\n",
            "         -2.4597e-02, -4.6822e-01, -6.2997e-01,  5.5987e-01, -2.4408e-01,\n",
            "         -5.5894e-02, -2.3682e-01, -1.4210e-02,  3.7141e-01, -5.4364e-01,\n",
            "          2.4708e-01,  6.6591e-01, -7.2269e-02, -6.6422e-02,  8.6786e-02,\n",
            "          1.1250e-01, -3.1154e-01,  2.4832e-01, -8.7105e-01, -1.1477e-01,\n",
            "          2.8246e-01, -1.9215e+00, -4.4351e-01, -8.6893e-01,  4.1442e-01,\n",
            "         -1.5844e-01,  1.0206e+00,  2.6618e-01, -4.8114e-01, -6.0077e-01,\n",
            "          3.7257e-01,  1.7866e-01, -6.2934e-01,  1.8443e-01,  1.3256e-01,\n",
            "          1.9591e-01,  2.6443e-02, -8.9381e-01, -1.0551e+00, -3.2133e-01,\n",
            "          6.1176e-01,  7.7298e-01,  5.9750e-01, -3.7292e-02, -2.9646e-03,\n",
            "         -1.9831e-02,  5.1908e-01,  2.7421e-01, -3.9299e-02, -5.9323e-01,\n",
            "          2.3288e-01,  1.1438e-01,  2.9018e-01,  5.6509e-01, -4.0396e-01,\n",
            "          1.5892e-01, -1.8226e-01, -8.6280e-02,  3.5291e-01,  8.2782e-02,\n",
            "          3.1250e-02,  6.5826e-01, -6.5853e-02,  8.9915e-02,  4.9200e-02,\n",
            "          3.1602e-01,  1.5337e-02, -2.2064e-01, -5.2850e-01, -7.6686e-01,\n",
            "         -3.3126e-01, -3.5588e-01, -3.1263e-01,  4.8936e-01,  9.4266e-01,\n",
            "          4.2889e-01,  1.3939e-02, -8.6887e-01,  4.1687e-01,  2.1447e-01,\n",
            "         -3.5438e-01,  1.6187e-01, -5.6585e-01,  1.8818e-01,  2.1879e-01,\n",
            "         -4.3793e-01, -3.4917e-01, -1.6108e-01, -8.1615e-02,  2.1118e-01,\n",
            "         -1.8806e-02,  7.6929e-01, -7.4366e-01,  8.2718e-01, -1.7129e-01,\n",
            "          7.8197e-01, -6.7172e-01,  5.4406e-01, -6.3593e-01, -8.4648e-01,\n",
            "          7.9686e-02, -6.8962e-01,  9.9830e-02, -1.4035e-01, -1.2739e-01,\n",
            "          7.2220e-01,  5.3046e-01,  3.2116e-01,  1.6048e-02,  8.8060e-01,\n",
            "          2.7630e-01,  2.3654e-01,  1.9473e-02,  9.5149e-02, -1.3083e+00,\n",
            "          1.6451e-01,  5.4269e-01, -9.5420e-01,  5.5821e-01, -7.1028e-01,\n",
            "         -9.7067e-01,  9.1530e-01, -4.4709e-01, -3.9697e-01,  1.3738e-01,\n",
            "         -3.1638e-01,  4.1699e-02,  1.9556e-01,  2.8576e-02, -6.4992e-01,\n",
            "         -1.7607e-01,  3.2369e-01, -2.4323e-01, -7.2384e-01, -8.8135e-02,\n",
            "         -4.8595e-01, -5.2433e-01,  4.6363e-02,  1.2564e-01, -7.0318e-02,\n",
            "         -3.2426e-01, -2.3545e-01, -2.5978e-01, -2.1087e-01,  6.1525e-02,\n",
            "          5.8999e-01, -6.5346e-01,  4.4109e-02,  2.8917e-01, -1.5559e-01,\n",
            "         -1.0440e+00,  4.3804e-01, -4.7128e-01,  3.8504e-01, -4.5634e-01,\n",
            "          4.5608e-01, -5.2691e-02, -2.9263e-02,  3.1915e-01, -2.1543e-02,\n",
            "          4.4823e-01,  3.0352e-02, -9.8531e-02, -4.4980e-01,  7.6887e-01,\n",
            "          1.7579e-01,  4.7158e-01,  7.9247e-01, -1.6954e-01,  4.4828e-02,\n",
            "         -7.9868e-01,  1.1104e-01,  3.1219e-01, -7.9014e-01, -6.3890e-02,\n",
            "          7.0124e-01, -1.3989e-01, -3.6326e-01, -1.4113e+00, -4.2714e-01,\n",
            "         -3.3453e-01,  2.5739e-01, -1.9016e-01, -1.8731e-02,  8.9380e-02,\n",
            "          3.2207e-01, -5.8732e-01, -6.3928e-02, -1.1702e-02,  1.5366e-01,\n",
            "          5.5455e-01, -3.2126e-01, -5.6582e-01,  1.4122e-01, -1.4005e-01,\n",
            "         -5.7277e-01,  1.2860e-01, -5.8568e-01,  6.9628e-01, -9.8720e-02,\n",
            "         -1.8151e-01, -3.2037e-01, -2.8078e-01,  4.8099e-01,  6.8008e-01,\n",
            "          3.3447e-01, -5.5781e-01, -3.3830e-01,  3.0258e-01,  2.0678e-01,\n",
            "         -4.1623e-01,  1.4989e-01, -1.3219e-01, -2.3128e-02, -1.7066e-01,\n",
            "         -2.9951e-01,  1.8416e-01, -2.4457e-01, -2.8012e-01,  6.7224e-01,\n",
            "         -1.5358e-01,  2.1048e-01,  8.8158e-02, -7.6272e-02,  5.5800e-02,\n",
            "          5.1746e-01, -7.0485e-01,  2.1775e-01,  1.8369e-02, -1.8262e-01,\n",
            "         -6.4182e-01, -5.1617e-01, -3.5467e-01,  9.3964e-01, -5.8129e-01,\n",
            "         -4.6054e-01, -4.2710e-01,  1.9007e-01,  4.6953e-02, -8.7612e-01,\n",
            "         -3.5661e-01,  2.6592e-01, -2.8130e-01, -8.9549e-01, -2.7883e-01,\n",
            "          6.9119e-01,  6.4110e-01, -1.3346e+00,  1.4882e-01,  3.5980e-01,\n",
            "         -1.6669e-02, -6.8460e-01, -2.4556e-01,  2.2888e-01,  1.6445e-01,\n",
            "         -3.6106e-01, -9.1236e-01, -1.4867e-01, -8.2620e-01, -9.0770e-01,\n",
            "         -9.6974e-02, -4.1080e-01, -3.3264e-01, -1.1186e+00,  1.0504e+00,\n",
            "         -7.2802e-02, -3.6574e-02, -4.6013e-01,  9.7395e-03, -5.5640e-01,\n",
            "         -7.0543e-01,  8.1332e-02, -3.6230e-01, -1.1429e+00, -5.7134e-01,\n",
            "         -2.0517e-01,  6.4297e-01, -3.3158e-01,  7.2823e-01, -6.8722e-02,\n",
            "          3.6524e-01, -3.4562e-01,  4.5704e-01,  7.4350e-02, -4.0668e-02,\n",
            "         -1.4650e-02, -3.5070e-01,  1.3819e-01,  7.6403e-02,  3.9375e-01,\n",
            "          8.2269e-02,  1.1257e-01, -4.3558e-01,  5.2612e-01, -8.6384e-02,\n",
            "         -2.9613e-01, -3.3068e-01,  5.5425e-01,  8.2638e-02, -2.7956e-02,\n",
            "          2.7813e-01,  1.0313e+00, -3.0488e-01,  6.8991e-01, -3.0357e-01,\n",
            "         -9.6137e-02,  1.8969e-01,  4.5131e-01,  3.3621e-01, -5.1049e-02,\n",
            "         -9.5624e-01,  2.8530e-01, -6.5776e-01,  4.6288e-01, -4.5659e-01,\n",
            "          1.4135e+00,  7.0422e-01, -8.9567e-01, -4.1579e-01, -4.3288e-02,\n",
            "         -4.2496e-01, -2.8591e-01,  3.6634e-01,  3.4911e-01, -8.4553e-01,\n",
            "         -8.1979e-01,  1.8781e-01, -1.4428e-01, -7.8827e-01,  3.0443e-01,\n",
            "         -2.2456e-01,  5.4599e-01,  1.1499e-01,  1.2674e-01,  2.6232e-01,\n",
            "         -5.0742e-01, -1.4579e-01,  1.5427e-01,  3.3253e-02,  1.2604e-01,\n",
            "          7.2958e-02, -1.6960e-02, -2.3323e-01,  9.5763e-01, -6.2736e-01,\n",
            "         -1.4914e-01, -4.8545e-01,  9.0646e-01, -8.3633e-02, -2.7652e-01,\n",
            "          2.4674e-01,  1.0146e-01,  4.8711e-01, -5.8654e-01,  5.3958e-01,\n",
            "         -2.8026e-01,  2.2847e-01,  4.5499e-01, -4.9766e-01,  1.2652e-01,\n",
            "          2.7612e-01, -3.6228e-01,  7.5199e-01,  2.2516e-01,  3.4277e-01,\n",
            "          2.0473e-01,  1.6633e-01, -7.1532e-01,  5.1923e-02,  4.6779e-02,\n",
            "         -7.4506e-02,  5.4293e-01, -7.0303e-01,  1.9854e-01,  2.6947e-01,\n",
            "         -7.0365e-01, -5.6929e-02, -4.0481e-01, -5.8154e-01,  4.2740e-01,\n",
            "          4.8332e-01, -4.9226e-01,  7.8305e-03, -1.0994e+00, -4.1703e-01,\n",
            "          4.2181e-01,  8.1631e-02,  6.5329e-01,  1.3190e+00, -2.3389e-01,\n",
            "          3.1153e-01, -7.0834e-01,  2.2252e-01,  2.9618e-01,  1.7338e-01,\n",
            "         -5.9888e-01, -8.7403e-01,  8.7114e-01,  2.1245e-01,  3.4190e-01,\n",
            "         -1.6029e-01,  7.4026e-01, -8.8376e-01, -2.5575e-02,  1.2237e-01,\n",
            "          8.1599e-01,  2.3616e-01,  1.4448e-02, -5.0305e-03,  7.6116e-01,\n",
            "         -2.6955e-01, -4.3859e-01,  4.2435e-01,  4.3299e-02, -7.0737e-01,\n",
            "         -1.7407e-01, -1.0467e+00,  7.0268e-01, -3.2046e-01,  4.3980e-02,\n",
            "         -4.5427e-02,  1.0784e+00,  1.2038e+00, -1.1309e+00, -7.3487e-01,\n",
            "          8.4406e-02,  3.9833e-01, -3.7732e-01, -5.9467e-02,  1.1214e+00,\n",
            "          2.7470e-01,  3.4009e-01, -5.0570e-01,  1.5640e-01, -2.0507e-01,\n",
            "         -2.8468e-01,  1.5058e-01, -2.6822e-01, -9.7476e-02, -4.0342e-01,\n",
            "         -9.5960e-01, -3.2105e-01, -1.3939e-01, -8.7429e-01,  6.8519e-01,\n",
            "         -6.4325e-01,  2.7909e-01,  5.0394e-01, -1.0945e+00,  3.1535e-01,\n",
            "         -4.1561e-02, -1.5499e-01, -1.3714e-01,  8.4334e-01, -6.5662e-01,\n",
            "          1.2232e-01,  3.4362e-01, -4.9708e-01, -2.6156e-01, -6.3050e-01,\n",
            "         -6.9362e-01, -6.7616e-01,  2.0255e-01, -1.9389e-01, -6.8753e-02,\n",
            "         -7.1378e-01, -7.5472e-01, -3.3861e-01,  2.8472e-01,  7.2478e-01,\n",
            "          5.7414e-01, -1.7554e-01, -6.6265e-01, -4.7806e-01, -9.2288e-02,\n",
            "         -3.5104e-01,  2.7866e-01,  6.7132e-01,  2.6179e-01, -3.5423e-01,\n",
            "         -1.8107e-01,  7.9297e-01, -1.8230e-02,  2.7117e-02, -5.5812e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "vqszlxEE0Bk0",
        "outputId": "a698b34d-00a8-4067-ddc5-180cb4c8eeaa"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "expected scalar type Long but found Float",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m outs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m lossval \u001b[38;5;241m=\u001b[39m \u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Calculate CrossEntropyLoss between outs and labels\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:1385\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1384\u001b[0m     \u001b[38;5;124;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3458\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3457\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3465\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
          ]
        }
      ],
      "source": [
        "# 4. mismatched tensor type\n",
        "import torch.nn as nn\n",
        "L = nn.CrossEntropyLoss()\n",
        "outs = torch.randn(5,5)\n",
        "labels = torch.Tensor([1,2,3,4,0])\n",
        "lossval = L(outs,labels) # Calculate CrossEntropyLoss between outs and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZwgwup_1dgS",
        "outputId": "aaf1de76-7ef2-4ca4-b87d-8482a3117249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6936)\n"
          ]
        }
      ],
      "source": [
        "# 4. mismatched tensor type (fixed)\n",
        "labels = labels.long()\n",
        "lossval = L(outs,labels)\n",
        "print(lossval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSuNdA8F06dK"
      },
      "source": [
        "**3. More on dataset and dataloader**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in84z_xu1rE6"
      },
      "source": [
        "A dataset is a cluster of data in a organized way. A dataloader is a loader which can iterate through the data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34zfh-c22Qqs"
      },
      "source": [
        "Let a dataset be the English alphabets \"abcdefghijklmnopqrstuvwxyz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TaiHofty1qKA"
      },
      "outputs": [],
      "source": [
        "dataset = \"abcdefghijklmnopqrstuvwxyz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0jwhVa12h3a"
      },
      "source": [
        "A simple dataloader could be implemented with the python code \"for\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bWC5Wwbv2egy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a\n",
            "b\n",
            "c\n",
            "d\n",
            "e\n",
            "f\n",
            "g\n",
            "h\n",
            "i\n",
            "j\n",
            "k\n",
            "l\n",
            "m\n",
            "n\n",
            "o\n",
            "p\n",
            "q\n",
            "r\n",
            "s\n",
            "t\n",
            "u\n",
            "v\n",
            "w\n",
            "x\n",
            "y\n",
            "z\n"
          ]
        }
      ],
      "source": [
        "for datapoint in dataset:\n",
        "  print(datapoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n33VKzkG2y2U"
      },
      "source": [
        "When using the dataloader, we often like to shuffle the data. This is where torch.utils.data.DataLoader comes in handy. If each data is an index (0,1,2...) from the view of torch.utils.data.DataLoader, shuffling can simply be done by shuffling an index array. \n",
        "\n",
        "（shuffle 打乱）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MXUUKQ65APf"
      },
      "source": [
        "torch.utils.data.DataLoader will need two imformation to fulfill its role. First, it needs to know the length of the data. Second, once torch.utils.data.DataLoader outputs the index of the shuffling results, the dataset needs to return the corresponding data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV5txsjK5j4j"
      },
      "source": [
        "Therefore, torch.utils.data.Dataset provides the imformation by two functions, `__len__()` and `__getitem__()` to support torch.utils.data.Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "A0IEkemJ5ajD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['g']\n",
            "['p']\n",
            "['h']\n",
            "['x']\n",
            "['i']\n",
            "['c']\n",
            "['s']\n",
            "['k']\n",
            "['v']\n",
            "['a']\n",
            "['d']\n",
            "['z']\n",
            "['u']\n",
            "['y']\n",
            "['o']\n",
            "['w']\n",
            "['n']\n",
            "['b']\n",
            "['r']\n",
            "['m']\n",
            "['e']\n",
            "['t']\n",
            "['l']\n",
            "['q']\n",
            "['f']\n",
            "['j']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.utils.data \n",
        "class ExampleDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  \n",
        "  def __getitem__(self,idx): # if the index is idx, what will be the data?\n",
        "    return self.data[idx]\n",
        "  \n",
        "  def __len__(self): # What is the length of the dataset\n",
        "    return len(self.data)\n",
        "\n",
        "dataset1 = ExampleDataset() # create the dataset\n",
        "dataloader = torch.utils.data.DataLoader(dataset = dataset1,shuffle = True,batch_size = 1)\n",
        "for datapoint in dataloader:\n",
        "  print(datapoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTt-ZTid9S2n"
      },
      "source": [
        "A simple data augmentation technique can be done by changing the code in `__len__()` and `__getitem__()`. Suppose we want to double the length of the dataset by adding in the uppercase letters, using only the lowercase dataset, you can change the dataset to the following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7Wn3BA2j-NXl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['K']\n",
            "['r']\n",
            "['A']\n",
            "['u']\n",
            "['j']\n",
            "['D']\n",
            "['Y']\n",
            "['o']\n",
            "['T']\n",
            "['x']\n",
            "['i']\n",
            "['w']\n",
            "['e']\n",
            "['G']\n",
            "['p']\n",
            "['O']\n",
            "['X']\n",
            "['y']\n",
            "['I']\n",
            "['L']\n",
            "['q']\n",
            "['R']\n",
            "['B']\n",
            "['f']\n",
            "['k']\n",
            "['Z']\n",
            "['l']\n",
            "['W']\n",
            "['n']\n",
            "['s']\n",
            "['g']\n",
            "['z']\n",
            "['m']\n",
            "['H']\n",
            "['t']\n",
            "['P']\n",
            "['C']\n",
            "['N']\n",
            "['S']\n",
            "['V']\n",
            "['a']\n",
            "['J']\n",
            "['v']\n",
            "['Q']\n",
            "['U']\n",
            "['M']\n",
            "['h']\n",
            "['E']\n",
            "['c']\n",
            "['d']\n",
            "['F']\n",
            "['b']\n"
          ]
        }
      ],
      "source": [
        "import torch.utils.data \n",
        "class ExampleDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  \n",
        "  def __getitem__(self,idx): # if the index is idx, what will be the data?\n",
        "    if idx >= len(self.data): # if the index >= 26, return upper case letter\n",
        "      return self.data[idx%26].upper()\n",
        "    else: # if the index < 26, return lower case, return lower case letter\n",
        "      return self.data[idx]\n",
        "  \n",
        "  def __len__(self): # What is the length of the dataset\n",
        "    return 2 * len(self.data) # The length is now twice as large\n",
        "\n",
        "dataset1 = ExampleDataset() # create the dataset\n",
        "dataloader = torch.utils.data.DataLoader(dataset = dataset1,shuffle = True,batch_size = 1)\n",
        "for datapoint in dataloader:\n",
        "  print(datapoint)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Pytorch Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
